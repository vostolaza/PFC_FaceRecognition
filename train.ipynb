{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install face_recognition"
      ],
      "metadata": {
        "id": "z0x6xsndhSrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "vBsH-hjviTFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xvf /content/drive/MyDrive/colorferet.tar"
      ],
      "metadata": {
        "id": "gmNz2-T1i6io"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQjRf4Hrf63q"
      },
      "outputs": [],
      "source": [
        "import face_recognition\n",
        "from email.mime import base\n",
        "from utils import IMAGE_PATH\n",
        "import numpy as np\n",
        "import random as rd\n",
        "import os\n",
        "import shutil\n",
        "import bz2\n",
        "import time\n",
        "import pickle\n",
        "import utils\n",
        "import json\n",
        "from sklearn import svm\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists('images/'):\n",
        "    os.mkdir('images/')"
      ],
      "metadata": {
        "id": "s6wY1XwbsCH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Putting all files in a single folder"
      ],
      "metadata": {
        "id": "TqbGT0ibqrRT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1,3):\n",
        "    dir = os.listdir(f'colorferet/dvd2/gray_feret_cd{i}/data/images')\n",
        "    for img in dir:\n",
        "        if img[-4:] != \".bz2\":\n",
        "            continue\n",
        "        fullname = f'colorferet/dvd2/gray_feret_cd{i}/data/images/' + img\n",
        "        with bz2.open(fullname) as fh, open('images/'+img[:-4], \"wb\") as fw:\n",
        "            shutil.copyfileobj(fh, fw)\n",
        "    for img in os.listdir('images'):\n",
        "        if img.endswith('.tif'):\n",
        "            code = img[:5]\n",
        "            print(code)\n",
        "            if not os.path.exists('images/' + code):\n",
        "                os.mkdir('images/' + code)\n",
        "            shutil.move('images/' + img,\n",
        "                        'images/' + code + '/' + img)"
      ],
      "metadata": {
        "id": "AeEdf337qvcc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate test set"
      ],
      "metadata": {
        "id": "FegVmfrNs5_L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from random import randint\n",
        "import os\n",
        "import json\n",
        "\n",
        "NSAMPLES = 100\n",
        "\n",
        "def generate_set(output_path, set):\n",
        "    d = {}\n",
        "    for i in range(NSAMPLES):\n",
        "        set = []\n",
        "        final_idx = -1\n",
        "        while (len(set) < 2):\n",
        "            idx = randint(0, 1209)\n",
        "            if idx in d: continue\n",
        "            if idx in set: continue\n",
        "            folder = 'images/' + str(idx).zfill(5)\n",
        "            if not os.path.exists(folder): continue\n",
        "            for img in os.listdir(folder):\n",
        "                if img.endswith(\".tif\") and ('fa' in img or 'fb' in img):\n",
        "                    img_path = folder + '/' + img\n",
        "                    set.append(img_path)\n",
        "                if len(set) == 2: break\n",
        "            final_idx = idx\n",
        "        while len(set) < 3:\n",
        "            idx = randint(0, 1209)\n",
        "            if idx == final_idx: continue\n",
        "            folder = 'images/' + str(idx).zfill(5)\n",
        "            if not os.path.exists(folder): continue\n",
        "            for img in os.listdir(folder):\n",
        "                if img.endswith(\".tif\") and ('fa' in img or 'fb' in img):\n",
        "                    img_path = folder + '/' + img\n",
        "                    set.append(img_path)\n",
        "                    break\n",
        "        d[final_idx] = set\n",
        "    with open(output_path, 'w') as f:\n",
        "        json.dump(d, f, indent=2)\n",
        "    return d\n",
        "\n",
        "x = {}\n",
        "train = generate_set('train_set.json', x)\n",
        "generate_set('test_set.json', train)"
      ],
      "metadata": {
        "id": "2q3e38uqs4Tf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IUVv12Yxf63w"
      },
      "outputs": [],
      "source": [
        "N_SAMPLES = 10\n",
        "PCA_N_COMPONENTS=25\n",
        "N_NEIGHBORS=10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1aBiIITFf63y"
      },
      "outputs": [],
      "source": [
        "def get_image(path):\n",
        "    picture = face_recognition.load_image_file(path)\n",
        "    return face_recognition.face_encodings(picture)[0]\n",
        "\n",
        "def generate_C1(set):\n",
        "    return get_image(set[0]) - get_image(set[1])\n",
        "\n",
        "def generate_C2(set):\n",
        "    return get_image(set[0]) - get_image(set[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hh4L3h5rf63z"
      },
      "outputs": [],
      "source": [
        "def get_sets(dataset='train'):\n",
        "    with open(\"{}_set.json\".format(dataset)) as f:\n",
        "        individuals = json.load(f)\n",
        "\n",
        "    C1 = []\n",
        "    C2 = []\n",
        "\n",
        "    count = 0\n",
        "    for dir, set in individuals.items():\n",
        "        # print(\"Generating C1 for {}...\".format(dir))\n",
        "        C1.append(generate_C1(set))\n",
        "        # print(\"Generating C2 for {}...\".format(dir))\n",
        "        C2.append(generate_C2(set))\n",
        "        if count == 50: break\n",
        "        \n",
        "    return[*C1, *C2], [*[1 for individual in C1], *[0 for individual in C2]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CSZNb-elf631"
      },
      "outputs": [],
      "source": [
        "def new_train_svm(X, y, kernel='rbf', C=0.5):\n",
        "    clf = svm.SVC(kernel=kernel, C=C)\n",
        "    \n",
        "    # print(f\"Fitting {kernel} kernel...\")\n",
        "    start = time.time()\n",
        "    clf.fit(X, y)\n",
        "    end = time.time()\n",
        "    # print(\"Fitted in {} seconds\".format(end - start))\n",
        "    \n",
        "    return clf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OH6g65kUf633"
      },
      "outputs": [],
      "source": [
        "def new_train_knn_pca(X, y, n_components=PCA_N_COMPONENTS,k=N_NEIGHBORS):\n",
        "    with open(\"train_set.json\") as f:\n",
        "        individuals = json.load(f)\n",
        "\n",
        "    C1 = []\n",
        "    C2 = []\n",
        "\n",
        "    for dir, set in individuals.items():\n",
        "        print(\"Generating C1 for {}...\".format(dir))\n",
        "        C1.append(generate_C1(set))\n",
        "        print(\"Generating C2 for {}...\".format(dir))\n",
        "        C2.append(generate_C2(set))\n",
        "    \n",
        "    X = [*C1, *C2]\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(X)\n",
        "    X = scaler.transform(X)\n",
        "    pca = PCA(n_components=n_components)\n",
        "    pca.fit(X)\n",
        "    X = pca.transform(X)\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    knn.fit(X, [*[1 for individual in C1], *[0 for individual in C2]])\n",
        "    return knn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AMTQ31-7f636"
      },
      "outputs": [],
      "source": [
        "def test_svm(clf):\n",
        "    with open(\"test_set.json\") as f:\n",
        "            individuals = json.load(f)\n",
        "\n",
        "    switch = 0\n",
        "    correct = 0\n",
        "    for dir, set in individuals.items():\n",
        "        if (switch):\n",
        "            res = clf.predict([get_image(set[0]) - get_image(set[1])])\n",
        "            if (res[0] == np.int64(1)): correct +=1\n",
        "            # print(type(res[0]))\n",
        "            switch = 0\n",
        "        else:\n",
        "            res = clf.predict([get_image(set[0]) - get_image(set[2])])\n",
        "            if (res[0] == np.int64(0)): correct +=1\n",
        "            # print(res[0])\n",
        "            switch = 1\n",
        "    accuracy = correct / len(individuals)\n",
        "    # print(\"Accuracy = {}\".format(accuracy))\n",
        "    return accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_svm(clf)"
      ],
      "metadata": {
        "id": "PvYrm3yIWCjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### K-fold cross validation"
      ],
      "metadata": {
        "id": "VLt8Mje1QszG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold"
      ],
      "metadata": {
        "id": "iIbr4ywKXIvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_validate_params_svm(X, y, C, kernel):\n",
        "    kf = KFold(n_splits=5)\n",
        "    kf.get_n_splits(X)\n",
        "\n",
        "    accuracies = []\n",
        "    for train_index, test_index in kf.split(X):\n",
        "        X_train, X_test = [X[i] for i in train_index], [X[i] for i in test_index]\n",
        "        y_train, y_test = [y[i] for i in train_index], [y[i] for i in test_index]\n",
        "\n",
        "        \n",
        "        clf = svm.SVC(C=C, kernel=kernel)\n",
        "        clf.fit(X_train, y_train)\n",
        "        y_hat = clf.predict(X_test)\n",
        "\n",
        "        score = 0\n",
        "        for predicted, target in zip(y_hat, y_test):\n",
        "            if y_hat == y_test:\n",
        "                score += 1\n",
        "\n",
        "        accuracies.append(score/len(y_test))\n",
        "\n",
        "    return np.mean(accuracies)\n",
        "\n",
        "\n",
        "def cross_validate_params_knn_pca(X, y, K, n_components):\n",
        "    kf = KFold(n_splits=5)\n",
        "    kf.get_n_splits(X)\n",
        "\n",
        "    accuracies = []\n",
        "\n",
        "    for train_index, test_index in kf.split(X):\n",
        "        X_train, X_test = [X[i] for i in train_index], [X[i] for i in test_index]\n",
        "        y_train, y_test = [y[i] for i in train_index], [y[i] for i in test_index]\n",
        "\n",
        "        scaler = StandardScaler()\n",
        "        scaler.fit(X_train)\n",
        "        X_train_scaled = scaler.transform(X_train)\n",
        "        pca = PCA(n_components=min(n_components, len(X_train)))\n",
        "        pca.fit(X_train_scaled)\n",
        "        X_scaled_reduced = pca.transform(X_train_scaled)\n",
        "        knn = KNeighborsClassifier(n_neighbors=K)\n",
        "        knn.fit(X_scaled_reduced, y_train)\n",
        "\n",
        "        scaler.fit(X_test)\n",
        "        X_test_scaled = scaler.transform(X_test)\n",
        "        pca.fit(X_test_scaled)\n",
        "        X_test_scaled_reduced = pca.transform(X_test_scaled)\n",
        "\n",
        "        y_hat = knn.predict(X_scaled_reduced)\n",
        "\n",
        "        score = 0\n",
        "        for predicted, target in zip(y_hat, y_test):\n",
        "            if y_hat == y_test:\n",
        "                score += 1\n",
        "\n",
        "        accuracies.append(score/len(y_test))\n",
        "    return np.mean(accuracies)\n",
        "\n",
        "\n",
        "def k_fold_cross_validation_svm(C_values, kernels):\n",
        "    X, y = get_sets('train')\n",
        "    for kernel in kernels:\n",
        "        for C in C_values:\n",
        "            score = cross_validate_params_svm(X, y, C, kernel)\n",
        "            print(\"C: {}, kernel: {}, accuracy: {}\".format(C, kernel, score))\n",
        "\n",
        "def k_fold_cross_validation_pca_knn(K_values, n_components_values):\n",
        "    X, y = get_sets('train')\n",
        "    for K in K_values:\n",
        "        for n_components in n_components_values:\n",
        "            #return cross_validate_params_knn_pca(X, y, K, n_components)\n",
        "            score = cross_validate_params_knn_pca(X, y, K, n_components)\n",
        "            print(\"k:{}, N components: {}, accuracy: {}\".format(K, n_components, score))"
      ],
      "metadata": {
        "id": "vIYUgReLS8Yn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aH3NTMFLf64A"
      },
      "outputs": [],
      "source": [
        "kernels = ['poly', 'rbf', 'sigmoid', 'linear']\n",
        "C_values = [0.01, 0.1, 1, 10, 100, 1000]\n",
        "k_fold_cross_validation_svm(C_values=C_values, kernels=kernels)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "K_values = [2, 4, 8, 16, 32]\n",
        "K_values = [8]\n",
        "n_components = [10, 20, 30, 40, 50, 60, 70, 80]\n",
        "k_fold_cross_validation_pca_knn(K_values=K_values, n_components_values=n_components)"
      ],
      "metadata": {
        "id": "r9qRlBEcb3o1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test"
      ],
      "metadata": {
        "id": "9zl8jzYUaemq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0VFPB1h4f638"
      },
      "outputs": [],
      "source": [
        "def train(kernel, C, X, y):\n",
        "    accuracy = -1\n",
        "    # while accuracy < 0.9:\n",
        "    clf = new_train_svm(X, y, kernel, C)\n",
        "    accuracy = test_svm(clf)\n",
        "    print(\"Accuracy = {}\".format(accuracy))\n",
        "    print(\"C = {}\".format(C))\n",
        "    print(\"Kernel = {}\".format(kernel))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F73lrJ-Tf63-"
      },
      "outputs": [],
      "source": [
        "X, y = get_sets('train')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train(kernel='rbf', C=1, X=X, y=y)"
      ],
      "metadata": {
        "id": "IBeasnRbzRKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k2NLhM0-f64D"
      },
      "outputs": [],
      "source": [
        "knn = new_train_knn_pca()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pe1bBkTXf64E"
      },
      "outputs": [],
      "source": [
        "correct = 0\n",
        "X, y = get_sets('test')\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X)\n",
        "X = scaler.transform(X)\n",
        "pca = PCA(n_components=PCA_N_COMPONENTS)\n",
        "pca.fit(X)\n",
        "X = pca.transform(X)\n",
        "count = 0\n",
        "\n",
        "for set in X:\n",
        "    if (count < 50):\n",
        "        res = knn.predict([set])\n",
        "        if (res[0] == np.int64(1)): correct +=1\n",
        "        count += 1\n",
        "    else:\n",
        "        res = knn.predict([set])\n",
        "        if (res[0] == np.int64(0)): correct +=1\n",
        "\n",
        "\n",
        "print(\"Accuracy = {}\".format(correct/len(individuals)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cehv86D7f64F"
      },
      "outputs": [],
      "source": [
        "knn.predict([get_image(\"images/00911/00911fa010_960530.tif\") - get_image(\"images/00510/00510fa010h_940519.tif\")])"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}